"""
LLM integration layer for ReachlyEngine.
Handles prompt construction, token control, and local inference via Ollama.
"""

